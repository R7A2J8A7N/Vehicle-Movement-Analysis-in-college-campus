{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9db775fa-dbdb-4afa-aff2-3ba318ac71fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c58c7d-0f8f-4985-bcdd-27d351f02789",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data1.yaml',mode='r') as f:\n",
    "    data_yaml = yaml.load(f,Loader=SafeLoader)\n",
    "    \n",
    "labels = data_yaml['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c74e317-51cc-4a78-97f7-a0e8a42c44bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_vechleDetection = cv2.dnn.readNetFromONNX('./vechleDetection/weights/best.onnx')\n",
    "yolo_vechleDetection.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "yolo_vechleDetection.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d77c1a3b-719f-4912-bfec-3d6591f02eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_numberPlate = cv2.dnn.readNetFromONNX('./numberPlate/weights/best.onnx')\n",
    "yolo_numberPlate.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "yolo_numberPlate.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed60b1b2-ef9a-41ea-aaf8-1c3dabbdcb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescaleFrame(frame,scale=0.75):\n",
    "    \n",
    "    width = int(frame.shape[1] * scale)\n",
    "    height = int(frame.shape[0] * scale)\n",
    "    dimensions = (width,height)\n",
    "    return cv2.resize(frame,dimensions,interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "237efc02-181a-40a4-9805-fabc99c5effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./Cars252.png')\n",
    "cv2.imshow('orginal',img)\n",
    "cv2.waitKey(0)\n",
    "image = rescaleFrame(img)\n",
    "# image = img.copy()\n",
    "row, col, d = image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe028fde-f5a9-46fd-a375-1dc285b5f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the YOLO prediction from the the image\n",
    "#  convert image into square image (array)\n",
    "max_rc = max(row,col)\n",
    "input_image = np.zeros((max_rc,max_rc,3),dtype=np.uint8)\n",
    "input_image[0:row,0:col] = image\n",
    "# step-2: get prediction from square array\n",
    "INPUT_WH_YOLO = 640\n",
    "blob = cv2.dnn.blobFromImage(input_image,1/255,(INPUT_WH_YOLO,INPUT_WH_YOLO),swapRB=True,crop=False)\n",
    "yolo_vechleDetection.setInput(blob)\n",
    "preds = yolo_vechleDetection.forward() # detection or prediction from YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fbf69f2-624f-405e-8304-5ea56561c8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 25200, 9)\n"
     ]
    }
   ],
   "source": [
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61b1cd7c-89fb-462f-a34e-ac0583f5352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non Maximum Supression\n",
    "# : filter detection based on confidence (0.4) and probability score (0.25)\n",
    "detections = preds[0]\n",
    "boxes = []\n",
    "confidences = []\n",
    "classes = []\n",
    "\n",
    "# widht and height of the image (input_image)\n",
    "image_w, image_h = input_image.shape[:2]\n",
    "x_factor = image_w/INPUT_WH_YOLO\n",
    "y_factor = image_h/INPUT_WH_YOLO\n",
    "\n",
    "for i in range(len(detections)):\n",
    "    row = detections[i]\n",
    "    confidence = row[4] # confidence of detection an object\n",
    "    if confidence > 0.4:\n",
    "        class_score = row[5:].max() # maximum probability from 20 objects\n",
    "        class_id = row[5:].argmax() # get the index position at which max probabilty occur\n",
    "        \n",
    "        if class_score > 0.25:\n",
    "            cx, cy, w, h = row[0:4]\n",
    "            # construct bounding from four values\n",
    "            # left, top, width and height\n",
    "            left = int((cx - 0.5*w)*x_factor)\n",
    "            top = int((cy - 0.5*h)*y_factor)\n",
    "            width = int(w*x_factor)\n",
    "            height = int(h*y_factor)\n",
    "            \n",
    "            box = np.array([left,top,width,height])\n",
    "            \n",
    "            # append values into the list\n",
    "            confidences.append(confidence)\n",
    "            boxes.append(box)\n",
    "            classes.append(class_id)\n",
    "            \n",
    "# clean\n",
    "boxes_np = np.array(boxes).tolist()\n",
    "confidences_np = np.array(confidences).tolist()\n",
    "\n",
    "# NMS\n",
    "index = cv2.dnn.NMSBoxes(boxes_np,confidences_np,0.25,0.45).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17e3cf63-bb66-4355-9960-03e31b68758b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93101e3c-cb2d-47d6-a4fa-a2d862194f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the Bounding\n",
    "for ind in index:\n",
    "    # extract bounding box\n",
    "    x,y,w,h = boxes_np[ind]\n",
    "    classes_id = 0\n",
    "    class_name = labels[classes_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2b7a2b1-a9e7-43af-b0b1-14218634fa84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 20, 332, 233, 'car')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y,w,h,class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cab8519b-b525-42e1-b6a6-12cefed42a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VechleImage = image[y:y+h, x:x+w]\n",
    "image = VechleImage.copy()\n",
    "row, col, d = image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c48cbe4-d84b-4e7f-807e-1abe361d9069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the YOLO prediction from the the image\n",
    "#  convert image into square image (array)\n",
    "max_rc = max(row,col)\n",
    "input_image = np.zeros((max_rc,max_rc,3),dtype=np.uint8)\n",
    "input_image[0:row,0:col] = image\n",
    "# step-2: get prediction from square array\n",
    "INPUT_WH_YOLO = 640\n",
    "blob = cv2.dnn.blobFromImage(input_image,1/255,(INPUT_WH_YOLO,INPUT_WH_YOLO),swapRB=True,crop=False)\n",
    "yolo_numberPlate.setInput(blob)\n",
    "preds = yolo_numberPlate.forward() # detection or prediction from YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fe1462e-a0c2-4cbc-8922-06053af9e896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 25200, 6)\n"
     ]
    }
   ],
   "source": [
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20dcdc3e-1f9a-4d78-a60b-c86274c98b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non Maximum Supression\n",
    "#  filter detection based on confidence (0.4) and probability score (0.25)\n",
    "detections = preds[0]\n",
    "boxes = []\n",
    "confidences = []\n",
    "classes = []\n",
    "\n",
    "# widht and height of the image (input_image)\n",
    "image_w, image_h = input_image.shape[:2]\n",
    "x_factor = image_w/INPUT_WH_YOLO\n",
    "y_factor = image_h/INPUT_WH_YOLO\n",
    "\n",
    "for i in range(len(detections)):\n",
    "    row = detections[i]\n",
    "    confidence = row[4] # confidence of detection an object\n",
    "    if confidence > 0.4:\n",
    "        class_score = row[5:].max() # maximum probability from 20 objects\n",
    "        class_id = row[5:].argmax() # get the index position at which max probabilty occur\n",
    "        \n",
    "        if class_score > 0.25:\n",
    "            cx, cy, w, h = row[0:4]\n",
    "            # construct bounding from four values\n",
    "            # left, top, width and height\n",
    "            left = int((cx - 0.5*w)*x_factor)\n",
    "            top = int((cy - 0.5*h)*y_factor)\n",
    "            width = int(w*x_factor)\n",
    "            height = int(h*y_factor)\n",
    "            \n",
    "            box = np.array([left,top,width,height])\n",
    "            \n",
    "            # append values into the list\n",
    "            confidences.append(confidence)\n",
    "            boxes.append(box)\n",
    "            classes.append(class_id)\n",
    "            \n",
    "# clean\n",
    "boxes_np = np.array(boxes).tolist()\n",
    "confidences_np = np.array(confidences).tolist()\n",
    "\n",
    "# NMS\n",
    "index = cv2.dnn.NMSBoxes(boxes_np,confidences_np,0.25,0.45).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a693dc8-e9d4-4cf9-959e-571964c5c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the Bounding\n",
    "for ind in index:\n",
    "    # extract bounding box\n",
    "    x,y,w,h = boxes_np[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc0ff09f-387f-48f8-b2f2-0c05cd60a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "numberPlateImage = image[y:y+h, x:x+w]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9fc2ac4-7fde-4fe5-a130-86553ac6dd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('yolo_prediction',numberPlateImage)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "330833f9-0461-467b-9e7d-29176fd931d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract # this is tesseract module \n",
    "#import matplotlib.pyplot as plt  \n",
    "import glob \n",
    "import os\n",
    "import string\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b18591a-1e79-44af-9300-097ec76d3251",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_tesseract = r\"C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe\"\n",
    "pytesseract.tesseract_cmd = path_to_tesseract \n",
    "res = ''.join(random.choices(string.ascii_uppercase +string.digits, k=6))\n",
    "vechlePhoto_address= res +'VP.png'\n",
    "numberPlate_Photo_address= res +'NP.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "361e8eb5-4536-4117-bb02-1b3e0606b7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(vechlePhoto_address,image)\n",
    "cv2.imwrite(numberPlate_Photo_address,numberPlateImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d8f96fa-6bee-4324-883e-6fa92045c04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rescaleFrame(frame,scale=1.2):\n",
    "    \n",
    "    width = int(frame.shape[1] * scale)\n",
    "    height = int(frame.shape[0] * scale)\n",
    "    dimensions = (width,height)\n",
    "    return cv2.resize(frame,dimensions,interpolation=cv2.INTER_CUBIC)\n",
    "numberPlateImage=rescaleFrame(numberPlateImage)\n",
    "resize_test_license_plate = cv2.resize( \n",
    "    numberPlateImage, None, fx = 2, fy = 2,  \n",
    "    interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imwrite(numberPlate_Photo_address,numberPlateImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d3e91a7-75f8-44d2-88be-169abfc3847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale_resize_test_license_plate = cv2.cvtColor( \n",
    "    resize_test_license_plate, cv2.COLOR_BGR2GRAY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5b2a988-7958-490a-9333-6e1884a7497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_blur_license_plate = cv2.GaussianBlur( \n",
    "    grayscale_resize_test_license_plate, (5, 5), 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2ac28f7-d62e-42a8-af0f-70b71794f524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAN54PJ\n"
     ]
    }
   ],
   "source": [
    "predicted_result = pytesseract.image_to_string(gaussian_blur_license_plate, lang ='eng', \n",
    "config ='--oem 3 -l eng --psm 6 -c tessedit_char_whitelist = ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789') \n",
    "filter_predicted_result = \"\".join(predicted_result.split()).replace(\":\", \"\").replace(\"-\", \"\").replace(\"!\",\"\").replace(\"`\",\"\").replace(\",\",\"\").replace('\"',\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\"|\",\"\").replace(\"'\",\"\").replace(\"_\",\"\").replace(\"s\",\"\").replace(\"a\",\"\").replace(\"b\",\"\").replace(\"c\",\"\").replace(\"d\",\"\").replace(\"e\",\"\").replace(\"f\",\"\").replace(\"g\",\"\").replace(\"h\",\"\").replace(\"i\",\"\").replace(\"j\",\"\").replace(\"k\",\"\").replace(\"l\",\"\").replace(\"m\",\"\").replace(\"n\",\"\").replace(\"o\",\"\").replace(\"p\",\"\").replace(\"q\",\"\").replace(\"r\",\"\").replace(\"s\",\"\").replace(\"t\",\"\").replace(\"u\",\"\").replace(\"v\",\"\").replace(\"w\",\"\").replace(\"x\",\"\").replace(\"y\",\"\").replace(\"z\",\"\")\n",
    "print(filter_predicted_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21f91f8e-5685-4a46-acb6-a1461a555517",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now()\n",
    "date = str(current_time.day)+'/'+str(current_time.month)+\"/\"+str(current_time.year)\n",
    "time = str(current_time.hour)+':'+str(current_time.minute)+\":\"+str(current_time.second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30126ba7-00d1-43ff-a0de-91bc7c9ba7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('GateEntry.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a95882f7-c15e-41db-97e5-8fc6b5cdcfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[len(df.index)] = [class_name,filter_predicted_result, date,time,vechlePhoto_address,numberPlate_Photo_address] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c1c52d9-2b3f-4ba0-9502-2f5377e0aee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VechleType</th>\n",
       "      <th>NumberPlate</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>vechlePhoto</th>\n",
       "      <th>NumberPlatePhoto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>car</td>\n",
       "      <td>CHIOOSE</td>\n",
       "      <td>9/7/2024</td>\n",
       "      <td>11:55:29</td>\n",
       "      <td>MZSRN2VP.png</td>\n",
       "      <td>MZSRN2NP.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>car</td>\n",
       "      <td>IMK3532</td>\n",
       "      <td>9/7/2024</td>\n",
       "      <td>11:58:5</td>\n",
       "      <td>LTJAXLVP.png</td>\n",
       "      <td>LTJAXLNP.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>car</td>\n",
       "      <td>CHIOOSE</td>\n",
       "      <td>9/7/2024</td>\n",
       "      <td>15:20:33</td>\n",
       "      <td>VRP0ZAVP.png</td>\n",
       "      <td>VRP0ZANP.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>car</td>\n",
       "      <td>IEL194y</td>\n",
       "      <td>9/7/2024</td>\n",
       "      <td>15:27:2</td>\n",
       "      <td>O43EODVP.png</td>\n",
       "      <td>O43EODNP.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>car</td>\n",
       "      <td>Q5836</td>\n",
       "      <td>9/7/2024</td>\n",
       "      <td>15:31:23</td>\n",
       "      <td>JE41X6VP.png</td>\n",
       "      <td>JE41X6NP.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>car</td>\n",
       "      <td>Q5836</td>\n",
       "      <td>9/7/2024</td>\n",
       "      <td>16:5:12</td>\n",
       "      <td>0JVPEKVP.png</td>\n",
       "      <td>0JVPEKNP.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>car</td>\n",
       "      <td>IEL194</td>\n",
       "      <td>9/7/2024</td>\n",
       "      <td>16:7:45</td>\n",
       "      <td>IAPSS9VP.png</td>\n",
       "      <td>IAPSS9NP.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>car</td>\n",
       "      <td>IEL194</td>\n",
       "      <td>14/7/2024</td>\n",
       "      <td>11:36:49</td>\n",
       "      <td>6VIIXTVP.png</td>\n",
       "      <td>6VIIXTNP.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>car</td>\n",
       "      <td>IEL194</td>\n",
       "      <td>14/7/2024</td>\n",
       "      <td>11:58:57</td>\n",
       "      <td>AQOR6OVP.png</td>\n",
       "      <td>AQOR6ONP.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>car</td>\n",
       "      <td>CHIOOSE</td>\n",
       "      <td>14/7/2024</td>\n",
       "      <td>12:0:18</td>\n",
       "      <td>6MQNZJVP.png</td>\n",
       "      <td>6MQNZJNP.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>car</td>\n",
       "      <td>CHIOOSE</td>\n",
       "      <td>14/7/2024</td>\n",
       "      <td>12:9:27</td>\n",
       "      <td>HZ1MCKVP.png</td>\n",
       "      <td>HZ1MCKNP.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>car</td>\n",
       "      <td>DAN54PJ</td>\n",
       "      <td>14/7/2024</td>\n",
       "      <td>12:10:35</td>\n",
       "      <td>44XKFIVP.png</td>\n",
       "      <td>44XKFINP.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VechleType NumberPlate       Date      Time   vechlePhoto NumberPlatePhoto\n",
       "0         car     CHIOOSE   9/7/2024  11:55:29  MZSRN2VP.png     MZSRN2NP.png\n",
       "1         car     IMK3532   9/7/2024   11:58:5  LTJAXLVP.png     LTJAXLNP.png\n",
       "2         car     CHIOOSE   9/7/2024  15:20:33  VRP0ZAVP.png     VRP0ZANP.png\n",
       "3         car     IEL194y   9/7/2024   15:27:2  O43EODVP.png     O43EODNP.png\n",
       "4         car       Q5836   9/7/2024  15:31:23  JE41X6VP.png     JE41X6NP.png\n",
       "5         car       Q5836   9/7/2024   16:5:12  0JVPEKVP.png     0JVPEKNP.png\n",
       "6         car      IEL194   9/7/2024   16:7:45  IAPSS9VP.png     IAPSS9NP.png\n",
       "7         car      IEL194  14/7/2024  11:36:49  6VIIXTVP.png     6VIIXTNP.png\n",
       "8         car      IEL194  14/7/2024  11:58:57  AQOR6OVP.png     AQOR6ONP.png\n",
       "9         car     CHIOOSE  14/7/2024   12:0:18  6MQNZJVP.png     6MQNZJNP.png\n",
       "10        car     CHIOOSE  14/7/2024   12:9:27  HZ1MCKVP.png     HZ1MCKNP.png\n",
       "11        car     DAN54PJ  14/7/2024  12:10:35  44XKFIVP.png     44XKFINP.png"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #df= df.drop(13)\n",
    "df.to_csv('GateEntry.csv',index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff7c8f0-8511-445e-a0f4-9dcfbc516c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
